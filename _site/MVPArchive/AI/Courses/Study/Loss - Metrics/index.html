<!doctype html>




<html
    dir="ltr"
    lang="en"
    
>
    <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content="#ffffff">
    <link rel="stylesheet" href="/assets/css/app.css">
    <link
        rel="shortcut icon"
        type="image/png"
        
            href="/favicon.png"
        
    >
    <script defer src="https://unpkg.com/alpinejs@3.9.0/dist/cdn.min.js"></script>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css">
    
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma-social@1/bin/bulma-social.min.css">
    
    <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Likelihood Function | MVPavan’s Notes</title>
<meta name="generator" content="Jekyll v3.9.5" />
<meta property="og:title" content="Likelihood Function" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Welcome to my GitHub Pages site." />
<meta property="og:description" content="Welcome to my GitHub Pages site." />
<link rel="canonical" href="http://localhost:4000/MVPArchive/AI/Courses/Study/Loss%20-%20Metrics/" />
<meta property="og:url" content="http://localhost:4000/MVPArchive/AI/Courses/Study/Loss%20-%20Metrics/" />
<meta property="og:site_name" content="MVPavan’s Notes" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Likelihood Function" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebPage","description":"Welcome to my GitHub Pages site.","headline":"Likelihood Function","url":"http://localhost:4000/MVPArchive/AI/Courses/Study/Loss%20-%20Metrics/"}</script>
<!-- End Jekyll SEO tag -->

    <!-- head scripts -->
</head>

    <body>
        
            <div class="">
    <script
        src="https://cdn.jsdelivr.net/npm/js-cookie@3.0.5/dist/js.cookie.min.js"
    ></script>

    <div class="container py-6 px-4" id="cookieBanner">
        <div class="columns">
            <div class="column is-fullwidth ">
                <div class="content">
                    <p>We use cookies on this site to enhance your user experience</p>
                    <p>
                        By clicking the Accept button, you agree to us doing so.
                        <a href="/cookie-policy/">More info on our cookie policy</a>
                    </p>
                </div>

                <div class="buttons">
                    <button class="button is-primary" onclick="acceptCookies()">Accept all cookies</button>
                    <button class="button is-primary" onclick="rejectCookies()">Reject all cookies</button>
                </div>
            </div>
        </div>
    </div>

    <script>
        function acceptCookies() {
            
            Cookies.set('showCookieBanner', 'false', { expires: 7, path: '/' });
            Cookies.set('cookiesAccepted', 'true', {expires: 7, path: '/'});
            toggleCookieBanner();
        }

        function rejectCookies() {
            Cookies.set('showCookieBanner', 'false', { expires: 7, path: '/' });
            toggleCookieBanner();
        }

        function toggleCookieBanner() {
            var showBanner = Cookies.get('showCookieBanner');
            var banner = document.getElementById('cookieBanner');

            if (showBanner === 'false') {
                banner.setAttribute('style', 'display: none;');
            } else {
                banner.setAttribute('style', 'display: block;');
            }
        }

        toggleCookieBanner();
    </script>
</div>

        
        <nav
    class="navbar is-primary "
    x-data="{ openNav: false }"
>
    <div class="container">
        <div class="navbar-brand">
            <a href="/" class="navbar-item">
                MVPavan's Notes
            </a>
            <a
                role="button"
                class="navbar-burger burger"
                aria-label="menu"
                aria-expanded="false"
                data-target="navMenu"
                :class="{ 'is-active': openNav }"
                x-on:click="openNav = !openNav"
            >
                <span aria-hidden="true"></span>
                <span aria-hidden="true"></span>
                <span aria-hidden="true"></span>
            </a>
        </div>
        <div class="navbar-menu" id="navMenu" :class="{ 'is-active': openNav }">
            <div class="navbar-start">
                <a href="/" class="navbar-item ">Home</a>
                
                    
                        
                            <a
                                href="/docs/"
                                class="navbar-item "
                            >Docs</a>
                        
                    
                
            </div>

            <div class="navbar-end">
                
            </div>
        </div>
    </div>
</nav>

        
            <section
    class="hero  is-medium  is-bold is-primary"
    
>
    <div class="hero-body ">
        <div class="container">
            <h1 class="title is-2">Likelihood Function</h1>
            <p class="subtitle is-3"></p>
            
        </div>
    </div>
</section>

        
        

        <section class="section">
            <div class="container">
                <div class="columns is-multiline">
                    
                    <div class="column is-8">
                        

                        

                        

                        

                        
<div class="content">
    <h2 id="1-likelihood-function">1. Likelihood Function</h2>
<p>In a probabilistic model, given some parameters $\theta$ and observed data <strong>x</strong>, the <strong>likelihood function</strong> measures how likely the observed data is under those parameters:</p>

<p>Given observed data ( x ) and model parameters ( $\theta$ ), the likelihood function is:</p>

\[L(\theta) = P(x | \theta)\]

<h2 id="2-log-likelihood">2. Log-Likelihood</h2>
<p>Since likelihoods are often small numbers (fractions close to zero), working with them directly can cause numerical instability. Instead, we take the <strong>log</strong> of the likelihood
Taking the logarithm of the likelihood:</p>

\[\log L(\theta) = \log P(x | \theta)\]

<h2 id="3-negative-log-likelihood-nll">3. Negative Log-Likelihood (NLL)</h2>
<p>Most machine learning models <strong>minimize</strong> loss functions (instead of maximizing likelihood). To turn <strong>log-likelihood maximization</strong> into a <strong>minimization problem</strong>, we take the negative of the log-likelihood.
To turn the maximization problem into a minimization problem:</p>

\[\text{NLL}(\theta) = - \log P(x | \theta)\]

<h3 id="a-nll-for-a-bernoulli-distribution-binary-classification">(a) NLL for a Bernoulli Distribution (Binary Classification)</h3>
<p>\(\text{NLL} = - \sum_{i=1}^{n} \left[ y_i \log p_i + (1 - y_i) \log (1 - p_i) \right]\)</p>

<p>where:</p>
<ul>
  <li>$y_i$ is the true label (0 or 1),</li>
  <li>$p_i$ is the predicted probability.</li>
</ul>

<h3 id="b-nll-for-a-gaussian-distribution-regression">(b) NLL for a Gaussian Distribution (Regression)</h3>
<p>\(\text{NLL} = \sum_{i=1}^{n} \left[ \frac{(x_i - \mu)^2}{2\sigma^2} + \log \sigma + \frac{1}{2} \log(2\pi) \right]\)</p>

<h2 id="4-cross-entropy-loss">4. Cross-Entropy Loss</h2>

<h3 id="general-formula-for-cross-entropy">General Formula for Cross-Entropy</h3>
<p>\(H(p, q) = - \sum_{i=1}^{C} p_i \log q_i\)</p>

<p>where:</p>
<ul>
  <li>$C$ is the number of classes</li>
  <li>$p_i$ is the true probability (usually 1 for the correct class, 0 for others)</li>
  <li>$q_i$  is the predicted probability</li>
</ul>

<h3 id="a-cross-entropy-for-binary-classification">(a) Cross-Entropy for Binary Classification</h3>
<p>\(L(y, \hat{y}) = - \left[ y \log(\hat{y}) + (1 - y) \log(1 - \hat{y}) \right]\)</p>

<p>where:</p>
<ul>
  <li>( $y$ ) is the true label (0 or 1),</li>
  <li>( $\hat{y}$ ) is the predicted probability for class 1.</li>
</ul>

<h3 id="b-cross-entropy-for-multi-class-classification">(b) Cross-Entropy for Multi-Class Classification</h3>
<p>For multi-class classification with <strong>softmax outputs</strong>:</p>

\[L(y, \hat{y}) = - \sum_{i=1}^{C} y_i \log(\hat{y}_i)\]

<p>Since only one  $y_i$ = 1 (one-hot encoding), this simplifies to:</p>

\[L(y, \hat{y}) = - \log(\hat{y}_{\text{correct}} )\]

<h2 id="5-relationship-between-nll-and-cross-entropy">5. Relationship Between NLL and Cross-Entropy</h2>
<p>Cross-entropy is equivalent to the <strong>negative log-likelihood (NLL)</strong> when using softmax probabilities:</p>

\[\text{Cross-Entropy Loss} = \text{Negative Log-Likelihood}\]

<h2 id="6-perplexity">6. Perplexity</h2>
<p>exponentiation of the average negative log-likelihood of a sequence. For a given sequence of words w<sub>1</sub>,w<sub>2</sub>,….,w<sub>N</sub> the perplexity is calculated as</p>

\[\text{PPL} = 2^{-\frac{1}{N} \sum_{i=1}^N \log_2 P(w_i \mid w_1, w_2, \ldots, w_{i-1})}\]

</div>

                    </div>
                    
                        <div class="column is-4-desktop is-4-tablet">
                            <p class="title is-4">Latest Posts</p>

<div class="columns is-multiline">
    
</div>

                        </div>
                    
                </div>
            </div>
        </section>
        
            <footer class="footer">
    <div class="container">
        
            <div class="columns is-multiline">
                
            </div>
        

        <div class="content is-small has-text-centered">
            <p class="">Theme built by <a href="https://www.csrhymes.com">C.S. Rhymes</a></p>
        </div>
    </div>
</footer>

        
        <script src="/assets/js/app.js" type="text/javascript"></script><!-- footer scripts -->
</body>
</html>
