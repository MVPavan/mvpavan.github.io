
Types of distributed training:
- Data Parallel: Replicate model across gpu and distribute data across each gpu.
	- DP
	- DDP
	- FSDP
	- Deepspeed:
		- Zero - 1,2,3
- Pipeline Parallel:
- Tensor Parallel:
- 